{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In diesem Notebook werden sämtliche Dimensionsreduktionsverfahren auf einen zufällig generierten Datensatz mit 10000 samples und 100 features angewandt. Die samplesize entspricht der in dieser Arbeit verwendeten sample size und die 100 features enspricht dem maximum an features nach der feature selection dieser arbeit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from constants import *\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def make_dataset(n_rows, n_features, train_size):\n",
    "    X, y = make_classification(n_samples=n_rows, random_state=RANDOM_STATE, n_features=n_features, n_informative=int(n_features/2), n_classes=3)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def run_benchmark(transformer, n_runs):\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        print(f\"run {i}\")\n",
    "        transformer.fit(X_train, y_train)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end- start\n",
    "    print(f\"runtime: {runtime} per run {runtime/n_runs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "n_rows=200000\n",
    "n_features=100\n",
    "train_size=10000\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_dataset(n_rows=n_rows, n_features=n_features, train_size=train_size)\n",
    "n_runs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "run 4\n",
      "run 5\n",
      "run 6\n",
      "run 7\n",
      "run 8\n",
      "run 9\n",
      "runtime: 0.6361427307128906 per run 0.06361427307128906\n"
     ]
    }
   ],
   "source": [
    "transformer = PCA(**PCA_PARAMS)\n",
    "transformer.set_params(**{\"n_components\": 2})\n",
    "run_benchmark(transformer, n_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark Kernel PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "run 4\n",
      "run 5\n",
      "run 6\n",
      "run 7\n",
      "run 8\n",
      "run 9\n",
      "runtime: 30.274785041809082 per run 3.027478504180908\n"
     ]
    }
   ],
   "source": [
    "transformer = KernelPCA(**KPCA_PARAMS)\n",
    "transformer.set_params(**{\"n_components\": 2})\n",
    "run_benchmark(transformer, n_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark LDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "run 4\n",
      "run 5\n",
      "run 6\n",
      "run 7\n",
      "run 8\n",
      "run 9\n",
      "runtime: 1.523341178894043 per run 0.1523341178894043\n"
     ]
    }
   ],
   "source": [
    "transformer = LinearDiscriminantAnalysis(**LDA_PARAMS)\n",
    "transformer.set_params(**{\"n_components\": 2})\n",
    "run_benchmark(transformer, n_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark K-MEANS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "run 4\n",
      "run 5\n",
      "run 6\n",
      "run 7\n",
      "run 8\n",
      "run 9\n",
      "runtime: 0.4961211681365967 per run 0.049612116813659665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "transformer = MiniBatchKMeans(**KMEANS_PARAMS)\n",
    "transformer.set_params(**{\"n_clusters\": 2})\n",
    "run_benchmark(transformer, n_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark UMAP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "run 4\n",
      "run 5\n",
      "run 6\n",
      "run 7\n",
      "run 8\n",
      "run 9\n",
      "runtime: 139.54862093925476 per run 13.954862093925476\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "transformer = UMAP(**UMAP_PARAMS)\n",
    "transformer.set_params(**{\"n_components\": 2})\n",
    "run_benchmark(transformer, n_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmark Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 1s 1ms/step - loss: 14.1970 - val_loss: 13.2927\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.9369 - val_loss: 12.8381\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.6422 - val_loss: 12.6576\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.4888 - val_loss: 12.5392\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.4012 - val_loss: 12.4739\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.3309 - val_loss: 12.4130\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.2766 - val_loss: 12.3686\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.2348 - val_loss: 12.3392\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.1990 - val_loss: 12.3107\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.1698 - val_loss: 12.2941\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.1432 - val_loss: 12.2581\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.1189 - val_loss: 12.2456\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0985 - val_loss: 12.2283\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0805 - val_loss: 12.2204\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0661 - val_loss: 12.2042\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0466 - val_loss: 12.1986\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0365 - val_loss: 12.1855\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0220 - val_loss: 12.1677\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 12.0100 - val_loss: 12.1605\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9957 - val_loss: 12.1409\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9821 - val_loss: 12.1331\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9694 - val_loss: 12.1235\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9585 - val_loss: 12.1178\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9508 - val_loss: 12.1101\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9413 - val_loss: 12.1074\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9325 - val_loss: 12.0996\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9249 - val_loss: 12.0909\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9170 - val_loss: 12.0853\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9117 - val_loss: 12.0838\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.9050 - val_loss: 12.0774\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8989 - val_loss: 12.0783\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8937 - val_loss: 12.0717\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8892 - val_loss: 12.0720\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8835 - val_loss: 12.0671\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8792 - val_loss: 12.0582\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8752 - val_loss: 12.0592\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8705 - val_loss: 12.0541\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8682 - val_loss: 12.0589\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8634 - val_loss: 12.0618\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8594 - val_loss: 12.0462\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8560 - val_loss: 12.0548\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8534 - val_loss: 12.0585\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8503 - val_loss: 12.0473\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8476 - val_loss: 12.0488\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8455 - val_loss: 12.0553\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8422 - val_loss: 12.0415\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8393 - val_loss: 12.0444\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8383 - val_loss: 12.0415\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8343 - val_loss: 12.0408\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8320 - val_loss: 12.0375\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8307 - val_loss: 12.0415\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8270 - val_loss: 12.0376\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8252 - val_loss: 12.0366\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8216 - val_loss: 12.0354\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8204 - val_loss: 12.0287\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8181 - val_loss: 12.0380\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8166 - val_loss: 12.0300\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8147 - val_loss: 12.0297\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8116 - val_loss: 12.0293\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8110 - val_loss: 12.0305\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8087 - val_loss: 12.0267\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8068 - val_loss: 12.0224\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8056 - val_loss: 12.0273\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8037 - val_loss: 12.0208\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.8012 - val_loss: 12.0199\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7998 - val_loss: 12.0218\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7985 - val_loss: 12.0233\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7967 - val_loss: 12.0199\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7951 - val_loss: 12.0231\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7954 - val_loss: 12.0184\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7910 - val_loss: 12.0228\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7905 - val_loss: 12.0226\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7898 - val_loss: 12.0149\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7858 - val_loss: 12.0157\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7857 - val_loss: 12.0171\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 11.7829 - val_loss: 12.0154\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7830 - val_loss: 12.0169\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7821 - val_loss: 12.0129\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7818 - val_loss: 12.0145\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7788 - val_loss: 12.0145\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7769 - val_loss: 12.0101\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7761 - val_loss: 12.0093\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7748 - val_loss: 12.0164\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7740 - val_loss: 12.0146\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7723 - val_loss: 12.0076\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7709 - val_loss: 12.0197\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7717 - val_loss: 12.0105\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7696 - val_loss: 12.0114\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7696 - val_loss: 12.0082\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7687 - val_loss: 12.0083\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7654 - val_loss: 12.0079\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7656 - val_loss: 12.0060\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7631 - val_loss: 12.0089\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7640 - val_loss: 12.0065\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7616 - val_loss: 12.0067\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7608 - val_loss: 12.0042\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7601 - val_loss: 12.0067\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7583 - val_loss: 12.0063\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7583 - val_loss: 12.0085\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7546 - val_loss: 12.0057\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7563 - val_loss: 12.0065\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7558 - val_loss: 12.0117\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7541 - val_loss: 12.0040\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7546 - val_loss: 12.0053\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7523 - val_loss: 12.0038\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7503 - val_loss: 12.0087\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7520 - val_loss: 12.0006\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7496 - val_loss: 12.0068\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7490 - val_loss: 12.0025\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7483 - val_loss: 12.0058\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7475 - val_loss: 12.0027\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7454 - val_loss: 11.9983\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7455 - val_loss: 12.0062\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7447 - val_loss: 12.0063\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7435 - val_loss: 12.0021\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7430 - val_loss: 12.0046\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7434 - val_loss: 12.0018\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7422 - val_loss: 12.0089\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7411 - val_loss: 12.0066\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7384 - val_loss: 12.0058\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7388 - val_loss: 11.9988\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - ETA: 0s - loss: 11.7368Restoring model weights from the end of the best epoch: 12.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7368 - val_loss: 12.0028\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7465 - val_loss: 12.0051\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7460 - val_loss: 12.0004\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7450 - val_loss: 12.0119\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7439 - val_loss: 12.0074\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7423 - val_loss: 12.0050\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7422 - val_loss: 12.0025\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7421 - val_loss: 12.0024\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7405 - val_loss: 12.0028\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7381 - val_loss: 12.0032\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7389 - val_loss: 12.0023\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7376 - val_loss: 11.9997\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7375 - val_loss: 12.0024\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7374 - val_loss: 11.9989\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7348 - val_loss: 12.0019\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7358 - val_loss: 12.0009\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7351 - val_loss: 12.0037\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7327 - val_loss: 11.9945\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7334 - val_loss: 12.0025\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7312 - val_loss: 12.0032\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7327 - val_loss: 11.9989\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7311 - val_loss: 12.0036\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7290 - val_loss: 12.0009\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7280 - val_loss: 11.9950\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7253 - val_loss: 12.0012\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7248 - val_loss: 11.9988\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7243 - val_loss: 11.9974\n",
      "Epoch 27/100\n",
      "205/207 [============================>.] - ETA: 0s - loss: 11.7268Restoring model weights from the end of the best epoch: 17.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7229 - val_loss: 11.9973\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7334 - val_loss: 12.0012\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7315 - val_loss: 12.0016\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7314 - val_loss: 11.9966\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7295 - val_loss: 12.0054\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7308 - val_loss: 12.0027\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7290 - val_loss: 12.0026\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7282 - val_loss: 12.0012\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7286 - val_loss: 11.9993\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7267 - val_loss: 12.0096\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7275 - val_loss: 11.9980\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7251 - val_loss: 11.9983\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7264 - val_loss: 11.9978\n",
      "Epoch 13/100\n",
      "200/207 [===========================>..] - ETA: 0s - loss: 11.7026Restoring model weights from the end of the best epoch: 3.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7251 - val_loss: 12.0030\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7297 - val_loss: 12.0077\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7299 - val_loss: 12.0076\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7291 - val_loss: 12.0042\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7289 - val_loss: 12.0021\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7294 - val_loss: 12.0028\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7269 - val_loss: 11.9974\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7274 - val_loss: 11.9970\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7261 - val_loss: 11.9963\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7254 - val_loss: 12.0010\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7256 - val_loss: 11.9910\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7251 - val_loss: 11.9961\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7249 - val_loss: 11.9990\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7257 - val_loss: 11.9958\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7220 - val_loss: 11.9998\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7222 - val_loss: 11.9957\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7223 - val_loss: 11.9993\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7240 - val_loss: 12.0032\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7219 - val_loss: 11.9969\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7202 - val_loss: 12.0016\n",
      "Epoch 20/100\n",
      "198/207 [===========================>..] - ETA: 0s - loss: 11.7014Restoring model weights from the end of the best epoch: 10.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7199 - val_loss: 12.0017\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7242 - val_loss: 11.9998\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7213 - val_loss: 11.9979\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7200 - val_loss: 11.9988\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7189 - val_loss: 11.9944\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7178 - val_loss: 11.9916\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7174 - val_loss: 11.9950\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7170 - val_loss: 11.9962\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7168 - val_loss: 11.9937\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7158 - val_loss: 11.9941\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7155 - val_loss: 11.9920\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7147 - val_loss: 11.9948\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7143 - val_loss: 11.9967\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7128 - val_loss: 11.9943\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7122 - val_loss: 12.0041\n",
      "Epoch 15/100\n",
      "205/207 [============================>.] - ETA: 0s - loss: 11.7138Restoring model weights from the end of the best epoch: 5.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7118 - val_loss: 11.9963\n",
      "Epoch 15: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7161 - val_loss: 11.9941\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7165 - val_loss: 11.9960\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7168 - val_loss: 11.9969\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7153 - val_loss: 11.9947\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7149 - val_loss: 11.9973\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7142 - val_loss: 11.9927\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7139 - val_loss: 11.9946\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7139 - val_loss: 11.9922\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7104 - val_loss: 11.9895\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7131 - val_loss: 11.9925\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7107 - val_loss: 11.9900\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7093 - val_loss: 11.9950\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7100 - val_loss: 11.9963\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7089 - val_loss: 11.9977\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7083 - val_loss: 11.9922\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7081 - val_loss: 11.9953\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7091 - val_loss: 11.9938\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7053 - val_loss: 11.9953\n",
      "Epoch 19/100\n",
      "205/207 [============================>.] - ETA: 0s - loss: 11.7086Restoring model weights from the end of the best epoch: 9.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7071 - val_loss: 11.9898\n",
      "Epoch 19: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7115 - val_loss: 11.9911\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7096 - val_loss: 11.9960\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7091 - val_loss: 11.9961\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7098 - val_loss: 11.9974\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7088 - val_loss: 11.9944\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7099 - val_loss: 11.9959\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7072 - val_loss: 11.9892\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7075 - val_loss: 11.9894\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7062 - val_loss: 11.9920\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7068 - val_loss: 11.9892\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7065 - val_loss: 11.9904\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7038 - val_loss: 11.9947\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7047 - val_loss: 11.9900\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7035 - val_loss: 11.9915\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7035 - val_loss: 11.9907\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7025 - val_loss: 11.9900\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7034 - val_loss: 11.9856\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7022 - val_loss: 11.9896\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7022 - val_loss: 11.9907\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7011 - val_loss: 11.9926\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7000 - val_loss: 11.9931\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6993 - val_loss: 11.9879\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7001 - val_loss: 11.9949\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7004 - val_loss: 11.9882\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6970 - val_loss: 11.9890\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6986 - val_loss: 11.9916\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - ETA: 0s - loss: 11.6961Restoring model weights from the end of the best epoch: 17.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6961 - val_loss: 11.9943\n",
      "Epoch 27: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7022 - val_loss: 11.9899\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7003 - val_loss: 11.9954\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7013 - val_loss: 11.9863\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6999 - val_loss: 11.9901\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7002 - val_loss: 11.9910\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.7004 - val_loss: 11.9914\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6989 - val_loss: 11.9923\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6985 - val_loss: 11.9955\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6975 - val_loss: 11.9917\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6984 - val_loss: 11.9871\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6975 - val_loss: 11.9839\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6949 - val_loss: 11.9860\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6954 - val_loss: 11.9864\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6950 - val_loss: 11.9899\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6961 - val_loss: 11.9874\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6942 - val_loss: 11.9905\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6945 - val_loss: 11.9931\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6946 - val_loss: 11.9900\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6940 - val_loss: 11.9911\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6931 - val_loss: 11.9851\n",
      "Epoch 21/100\n",
      "206/207 [============================>.] - ETA: 0s - loss: 11.6894Restoring model weights from the end of the best epoch: 11.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6928 - val_loss: 11.9877\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6954 - val_loss: 11.9969\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6967 - val_loss: 11.9911\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6958 - val_loss: 11.9847\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6937 - val_loss: 11.9927\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6962 - val_loss: 11.9929\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6934 - val_loss: 11.9875\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6933 - val_loss: 11.9912\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6930 - val_loss: 11.9878\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6935 - val_loss: 11.9873\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6932 - val_loss: 11.9849\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6912 - val_loss: 11.9888\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6912 - val_loss: 11.9965\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - ETA: 0s - loss: 11.6933Restoring model weights from the end of the best epoch: 3.\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 11.6933 - val_loss: 11.9852\n",
      "Epoch 13: early stopping\n",
      "runtime: 61.51878070831299 per run 6.151878070831299\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "params = AUTOENCODER_PARAMS\n",
    "\n",
    "# amount features in X\n",
    "#X_n_features = len(X_train.columns)\n",
    "X_n_features = n_features\n",
    "\n",
    "# This is the size of our encoded representations = n new features\n",
    "encoding_dim = min(10, int(math.sqrt(X_n_features)))\n",
    "\n",
    "# Encoder\n",
    "input_layer = keras.Input(shape=(X_n_features,), name=\"input_layer\")\n",
    "x = layers.Dense(int(X_n_features / 2), activation=params[\"activation\"], name=\"hidden_encode\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "x = layers.Dense(encoding_dim, activation=params[\"activation\"], name=\"encode_layer\", activity_regularizer=regularizers.l1(10e-5))(x)\n",
    "encoder_model = keras.Model(input_layer, x)\n",
    "\n",
    "# Decoder layer\n",
    "x = layers.Dense(int(X_n_features / 2), activation=params[\"activation\"], name=\"hidden_decode\", activity_regularizer=regularizers.l1(10e-5))(x)\n",
    "x = layers.Dense(X_n_features, activation=params[\"activation\"], name=\"decode\", activity_regularizer=regularizers.l1(10e-5))(x)\n",
    "\n",
    "# autoencoder model\n",
    "autoencoder = keras.Model(input_layer, x)\n",
    "autoencoder.compile(optimizer=params[\"optimizer\"], loss=params[\"loss\"])\n",
    "\n",
    "# specify how early stopping works\n",
    "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # \"loss\" -> train loss, \"val_loss\" -> validation loss\n",
    "    patience=params[\"early_stopping_patience\"],\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(n_runs):\n",
    "    # fit\n",
    "    autoencoder.fit(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        epochs=params[\"epochs\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        validation_split=params[\"validation_split\"],\n",
    "        # use_multiprocessing=True, # seems to have no effect. afaik tensorflow uses all cores by default on a single pc\n",
    "        callbacks=[callback_early_stopping],\n",
    "    )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "runtime = end- start\n",
    "print(f\"runtime: {runtime} per run {runtime/n_runs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X, y = make_classification(n_samples=n_rows, random_state=RANDOM_STATE, n_features=n_features, n_informative=int(n_features/2), n_classes=3)\n",
    "n_rows=200000\n",
    "n_features=100\n",
    "train_size=10000\n",
    "\n",
    "--------\n",
    "\n",
    "pca:            runtime: 0.6361427307128906 per run 0.06361427307128906\n",
    "kpca:           runtime: 30.274785041809082 per run 3.027478504180908\n",
    "lda:            runtime: 1.523341178894043 per run 0.1523341178894043\n",
    "k-means:        runtime: 0.4961211681365967 per run 0.049612116813659665\n",
    "umap:           runtime: 139.54862093925476 per run 13.954862093925476\n",
    "autoencoder:    runtime: 61.51878070831299 per run 6.151878070831299\n",
    "\n",
    "\n",
    "--------\n",
    "pca runtime = 1 setzen\n",
    "\n",
    "pca:            1\n",
    "kpca:           7.59\n",
    "lda:            2.39\n",
    "k-means:        0.78\n",
    "umap:           219.37\n",
    "autoencoder:    96.71\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}